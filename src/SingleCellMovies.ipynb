{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import napari\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from napari_animation import Animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data location & settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path_base = \"/data/\"\n",
    "\n",
    "# These paths should be present within the base directory\n",
    "path_img = path_base + \"/Image/\"\n",
    "path_track = path_base + \"/Tracks/\"\n",
    "path_movies = path_base + \"/Movies/\"\n",
    "\n",
    "# Name of imaging dataset\n",
    "filename = \"sample.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop buffer size in pixels\n",
    "buffer = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load imaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load stitch\n",
    "Axis: [t, c, y, x]\n",
    "'''\n",
    "data_img = np.load(path_img + filename, mmap_mode = 'r') #enabled lazy loading by default\n",
    "print(data_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load tracking data\n",
    "Columns: [t, y, x, IDTrack]\n",
    "'''\n",
    "\n",
    "df_tracks = pd.read_csv(path_track + filename + \"_tracks.csv\", sep = \",\", decimal = \".\")\n",
    "print(df_tracks.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track inclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold for minimum length of tracks to include (0 = no limit)\n",
    "length_limit = df_tracks['t'].max() * .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot track length distribution as sanity check\n",
    "track_lengths = df_tracks.groupby(['IDTrack']).size().reset_index(name = 'count')\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(track_lengths['count'])\n",
    "plt.xlabel('IDTrack')\n",
    "plt.axvline(x = length_limit, color = 'red', linestyle = '--', label = 'Threshold')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Entries for Each ID')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Track IDs that meet length criteria, reindex for later reference in cropped stack\n",
    "tracks_of_interest = track_lengths[track_lengths['count'] >= length_limit][['IDTrack']].reset_index(drop = True).reset_index()\n",
    "tracks_of_interest.to_csv(path_movies + filename + '_StabilizedIndex.csv', index = False)\n",
    "print(tracks_of_interest.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter tracking table, and associate reindexed track IDs\n",
    "df_tracks_filter = df_tracks.merge(tracks_of_interest, on = ['IDTrack'])\n",
    "print('event percent retained', round(len(df_tracks_filter)/len(df_tracks)*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build crop & padding table\n",
    "img_width = data_img.shape[-1]\n",
    "img_height = data_img.shape[-2]\n",
    "\n",
    "df_tracks_filter['x_int'] = df_tracks_filter['x'].round(0).astype(int)\n",
    "df_tracks_filter['y_int'] = df_tracks_filter['y'].round(0).astype(int)\n",
    "\n",
    "# calculate min and max X and Y by buffer from track centroid\n",
    "df_tracks_filter['x_min'] = df_tracks_filter['x_int'] - buffer\n",
    "df_tracks_filter['x_max'] = df_tracks_filter['x_shift'] + buffer\n",
    "df_tracks_filter['y_min'] = df_tracks_filter['y_shift'] - buffer\n",
    "df_tracks_filter['y_max'] = df_tracks_filter['y_shift'] + buffer\n",
    "\n",
    "# calculate padding pixels in X and Y\n",
    "df_tracks_filter['pad_left'] = np.abs(np.clip(df_tracks_filter['x_min'], None, 0))\n",
    "df_tracks_filter['pad_right'] = np.abs(np.clip(df_tracks_filter['x_max'] - img_width, 0, None))\n",
    "df_tracks_filter['pad_top'] = np.abs(np.clip(df_tracks_filter['y_min'], None, 0))\n",
    "df_tracks_filter['pad_bottom'] = np.abs(np.clip(df_tracks_filter['y_max'] - img_height, 0, None))\n",
    "\n",
    "# clip min and max to image dims\n",
    "df_tracks_filter['x_min'] = np.clip(df_tracks_filter['x_min'], 0, None)\n",
    "df_tracks_filter['y_min'] = np.clip(df_tracks_filter['y_min'], 0, None)\n",
    "df_tracks_filter['x_max'] = np.clip(df_tracks_filter['x_max'], None, img_width)\n",
    "df_tracks_filter['y_max'] = np.clip(df_tracks_filter['y_max'], None, img_height)\n",
    "\n",
    "print(df_tracks_filter.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init empty np array to paste data in\n",
    "sizes_stab = {\n",
    "    'T': data_img.shape[0],\n",
    "    'P': len(tracks_of_interest),\n",
    "    'X': buffer * 2,\n",
    "    'Y': buffer * 2}\n",
    "print(sizes_stab)\n",
    "\n",
    "stabilized_movie_img = np.zeros(shape = list(sizes_stab.values()), dtype = np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort crop table (moe efficient with lazy timeframe loading) \n",
    "crop_table = df_tracks_filter.sort_values(by = ['t']).reset_index(drop = True)\n",
    "crop_table_np = crop_table[['index', 't', 'x_min', 'x_max', 'y_min', 'y_max', 'pad_left', 'pad_right', 'pad_top', 'pad_bottom']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop imaging data and paste into np array according to crop table\n",
    "last_T = None\n",
    "\n",
    "for i in tqdm(crop_table_np):\n",
    "    index, T = i[:2]\n",
    "\n",
    "    # slice T + compute\n",
    "    if (T != last_T):\n",
    "        img = data_img[T].compute()\n",
    "        \n",
    "        # set which T and P last computed\n",
    "        last_T = T\n",
    "\n",
    "    # Crop parameters\n",
    "    x_min, x_max, y_min, y_max = i[-8:-4]\n",
    "    pad_left, pad_right, pad_top, pad_bottom = i[-4:]\n",
    "    \n",
    "    # Crop (all channels)\n",
    "    crop = img[:, y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    # pad tile image if required\n",
    "    if (np.sum(i[-4:]) > 0):\n",
    "        pad_tuple = ((0, 0), (pad_top, pad_bottom), (pad_left, pad_right))\n",
    "        crop = np.pad(crop, pad_tuple, mode = 'constant')\n",
    "\n",
    "    # paste tile image\n",
    "    stabilized_movie_img[T, index] = crop\n",
    "\n",
    "# Store array to disk\n",
    "np.save(path_movies + filename + \"_Stabilized.npy\", stabilized_movie_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Napari (individual tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stabilized_movie_img' not in locals():\n",
    "    stabilized_movie_img = np.load(path_movies + filename + \"_Stabilized.npy\")\n",
    "print(stabilized_movie_img.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image movie\n",
    "layerImage = viewer.add_image(stabilized_movie_img,\n",
    "                 channel_axis = 2,\n",
    "                 blending = 'additive',\n",
    "                 visible = True,\n",
    "                 gamma = 1)\n",
    "viewer.dims.axis_labels = ['T', 'Object', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make into grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_grid_positions(df, grid_shape):\n",
    "    num_rows, num_cols = grid_shape\n",
    "    total_elements = num_rows * num_cols\n",
    "\n",
    "    # Calculate row and column numbers for each row\n",
    "    df['Row'] = (df.index // num_cols) % num_rows\n",
    "    df['Column'] = df.index % num_cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload in case of making a new grid in a new session\n",
    "if 'tracks_of_interest' not in locals():\n",
    "    tracks_of_interest = pd.read_csv(path_movies + filename + '_StabilizedIndex.csv')\n",
    "print(tracks_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick A (random subset) or B (specific subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Select random tracks\n",
    "tracks_of_interest_sample = tracks_of_interest.sample(n = 5*5*5).reset_index(drop = True)\n",
    "print(tracks_of_interest_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Select specific tracks\n",
    "tracksOfInterest = [100, 200]\n",
    "tracks_of_interest_sample = tracks_of_interest[tracks_of_interest['IDTrack'].isin(tracksOfInterest)].reset_index(drop = True)\n",
    "print(tracks_of_interest_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define single grid dimensions\n",
    "rows, cols = [5, 5]\n",
    "grid_n = rows * cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign tracks to position in grid and pages (sets) if overflowing 1 grid\n",
    "tracks_of_interest_sample['set'] = [i // grid_n for i in range(len(tracks_of_interest_sample))]\n",
    "tracks_of_interest_sample = assign_grid_positions(tracks_of_interest_sample, (rows, cols))\n",
    "\n",
    "# Assign track pixel positions in grid\n",
    "tracks_of_interest_sample['x_start'] = tracks_of_interest_sample['Column'] * 2 * buffer\n",
    "tracks_of_interest_sample['x_stop'] = tracks_of_interest_sample['Column'] * 2* buffer + 2 * buffer\n",
    "tracks_of_interest_sample['y_start'] = tracks_of_interest_sample['Row'] * 2 * buffer\n",
    "tracks_of_interest_sample['y_stop'] = tracks_of_interest_sample['Row'] * 2* buffer + 2 * buffer\n",
    "\n",
    "# Store grid layout table\n",
    "tracks_of_interest_sample.to_csv(path_movies + filename + '_StabilizedGridIndex.csv', index = False)\n",
    "print(tracks_of_interest_sample.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate empty numpy array for grid\n",
    "shapeIn = stabilized_movie_img.shape\n",
    "shapeGridAll = [shapeIn[0], #T\n",
    "                tracks_of_interest_sample['set'].max() + 1, #ObjectIndex\n",
    "                shapeIn[2], #Channels\n",
    "                rows * buffer * 2,\n",
    "                cols * buffer * 2]\n",
    "stabilized_movie_img_grid = np.zeros(shape = shapeGridAll, dtype = np.uint16)\n",
    "stabilized_movie_img_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste single object movies at calculated positions in grid\n",
    "tracks_of_interest_sample_np = tracks_of_interest_sample[['index', 'set', 'Row', 'Column', 'y_start', 'y_stop', 'x_start', 'x_stop']].to_numpy()\n",
    "for i in tqdm(tracks_of_interest_sample_np):\n",
    "    index, Set, Row, Column, y_start, y_stop, x_start, x_stop = i\n",
    "    \n",
    "    # isolate cell (all T & C)\n",
    "    img = stabilized_movie_img[:, index]\n",
    "    # paste\n",
    "    stabilized_movie_img_grid[:, Set, :, y_start:y_stop, x_start:x_stop] = img\n",
    "\n",
    "# Store array to disk\n",
    "np.save(path_movies + filename + \"_Stabilized_grid_subset.npy\", stabilized_movie_img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Napari (grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stabilized_movie_img_grid' not in locals():\n",
    "    stabilized_movie_img_grid = np.load(path_movies + filename + \"_Stabilized_grid_subset.npy\")\n",
    "print(stabilized_movie_img_grid.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image movie\n",
    "layerImage = viewer.add_image(stabilized_movie_img_grid,\n",
    "                 channel_axis = 2,\n",
    "                 blending = 'additive',\n",
    "                 visible = True,\n",
    "                 gamma = 1)\n",
    "viewer.dims.axis_labels = ['T', 'Set', 'Y', 'X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create annotated crop outlines (IDTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bbox(bbox_extents):\n",
    "    \"\"\"Get the coordinates of the corners of a\n",
    "    bounding box from the extents\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bbox_extents : list (4xN)\n",
    "        List of the extents of the bounding boxes for each of the N regions.\n",
    "        Should be ordered: [min_row, min_column, max_row, max_column]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bbox_rect : np.ndarray\n",
    "        The corners of the bounding box. Can be input directly into a\n",
    "        napari Shapes layer.\n",
    "    \"\"\"\n",
    "    minr = bbox_extents[0]\n",
    "    minc = bbox_extents[1]\n",
    "    maxr = bbox_extents[2]\n",
    "    maxc = bbox_extents[3]\n",
    "\n",
    "    bbox_rect = np.array(\n",
    "        [[minr, minc], [maxr, minc], [maxr, maxc], [minr, maxc]]\n",
    "    )\n",
    "    bbox_rect = np.moveaxis(bbox_rect, 2, 0)\n",
    "\n",
    "    return bbox_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stabilized_movie_img_grid' not in locals():\n",
    "   tracks_of_interest_sample = pd.read_csv(path_movies + filename + '_StabilizedGridIndex.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tile position + index layer (rect + text)\n",
    "features_tiles = {\n",
    "    'label': 'ID' + tracks_of_interest_sample['IDTrack'].astype(str).str.zfill(4),\n",
    "    'bbox-0': tracks_of_interest_sample['y_start'],\n",
    "    'bbox-1': tracks_of_interest_sample['x_start'],\n",
    "    'bbox-2': tracks_of_interest_sample['y_stop'],\n",
    "    'bbox-3': tracks_of_interest_sample['x_stop']\n",
    "}\n",
    "\n",
    "# Translate coordinates into bounding box\n",
    "bbox_tile = make_bbox([features_tiles[f'bbox-{i}'] for i in range(4)])\n",
    "\n",
    "# Append set axis for display\n",
    "bbox_tile = [np.concatenate((np.tile([tracks_of_interest_sample.loc[i, 'set']], (4, 1)), bbox), axis = 1) for i, bbox in enumerate(bbox_tile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the display parameters for the text\n",
    "text_parameters = {\n",
    "    'string': '{label}',\n",
    "    'size': 12,\n",
    "    'color': 'yellow',\n",
    "    'anchor': 'upper_left',\n",
    "    'translation': [0, 0],\n",
    "    'opacity': 1\n",
    "}\n",
    "\n",
    "shapes_layer = viewer.add_shapes(\n",
    "    bbox_tile,\n",
    "    face_color = 'transparent',\n",
    "    edge_color = 'yellow',\n",
    "    edge_width = 2,\n",
    "    properties = features_tiles,\n",
    "    text = text_parameters,\n",
    "    name = 'bbox_index',\n",
    "    opacity = 0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render animation of grid from Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate animation\n",
    "animation = Animation(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First keyframe (start of timelapse)\n",
    "viewer.dims.set_current_step(0, 0)\n",
    "animation.capture_keyframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last keyframe (end of timelapse)\n",
    "length_movie = stabilized_movie_img_grid.shape[0]\n",
    "viewer.dims.set_current_step(0, length_movie)\n",
    "animation.capture_keyframe(steps = length_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render command\n",
    "animation.animate(path_movies + datetime.today().strftime('%Y%m%d') + '_GridMovie.mov', canvas_only = True, quality = 9, fps = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
